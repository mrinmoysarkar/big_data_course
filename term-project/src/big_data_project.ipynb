{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-white')\n",
    "import seaborn as sns\n",
    "sns.set_style('white')\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.transform import resize\n",
    "\n",
    "# from keras.preprocessing.image import load_img\n",
    "# from keras import Model\n",
    "# from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "# from keras.models import load_model\n",
    "# from keras.optimizers import Adam\n",
    "# from keras.utils.vis_utils import plot_model\n",
    "# from keras.preprocessing.image import ImageDataGenerator\n",
    "# from keras.layers import Input, Conv2D, Conv2DTranspose, MaxPooling2D, concatenate, Dropout\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size_ori = 101\n",
    "img_size_target = 128\n",
    "\n",
    "def upsample(img):\n",
    "    if img_size_ori == img_size_target:\n",
    "        return img\n",
    "#     return resize(img, (img_size_target, img_size_target), mode='constant', preserve_range=True)\n",
    "    delta = img_size_target-img_size_ori\n",
    "    d1 = delta//2\n",
    "    d2 = delta-d1\n",
    "    y = np.lib.pad(img, ((d1, d2), (d1, d2)), 'constant', constant_values=0)\n",
    "    return y.ravel()\n",
    "\n",
    "def downsample(img):\n",
    "    if img_size_ori == img_size_target:\n",
    "        return img\n",
    "    return resize(img, (img_size_ori, img_size_ori), mode='constant', preserve_range=True)\n",
    "\n",
    "class batch_generator():\n",
    "    def __init__(self,data):\n",
    "        self.index = 0\n",
    "        data['images'] = data['images'].apply(upsample)\n",
    "        data['masks'] = data['masks'].apply(upsample)\n",
    "        self.images = data['images'].values\n",
    "        self.masks = data['masks'].values\n",
    "        \n",
    "    def get_xy_batch(self,batch_size):\n",
    "        x = self.images[self.index:self.index+batch_size]\n",
    "        y = self.masks[self.index:self.index+batch_size]\n",
    "        self.index += batch_size\n",
    "        return np.array(x.tolist()),np.array(y.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"../data/train.csv\", index_col=\"id\", usecols=[0])\n",
    "depths_df = pd.read_csv(\"../data/depths.csv\", index_col=\"id\")\n",
    "train_df = train_df.join(depths_df)\n",
    "test_df = depths_df[~depths_df.index.isin(train_df.index)]\n",
    "total_no_of_train_samples = train_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8b717dff9a6413fa8d34b83256c8934",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_df[\"images\"] = [np.array(load_img(\"../data/train/images/{}.png\".format(idx), color_mode=\"grayscale\")) / 255 for idx in tqdm_notebook(train_df.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "491b5afd8e744f7481a67f4dc41cf352",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_df[\"masks\"] = [np.array(load_img(\"../data/train/masks/{}.png\".format(idx), color_mode=\"grayscale\")) / 255 for idx in tqdm_notebook(train_df.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(train_df.head())\n",
    "# train_df_temp = train_df\n",
    "# train_df_temp['images'] = train_df_temp['images'].apply(upsample)\n",
    "# train_df_temp['masks'] = train_df_temp['masks'].apply(upsample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "bg = batch_generator(train_df)\n",
    "# x_train,y_train = bg.get_xy_batch(batch_size=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(list(y_train))\n",
    "# print(np.array(x_train))\n",
    "# print(type(x_train))\n",
    "# x_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "\n",
    "x = tf.placeholder(tf.float32,shape=[None,16384])\n",
    "y_true = tf.placeholder(tf.float32,shape=[None,16384])\n",
    "\n",
    "inputs = tf.reshape(x,[-1,128,128,1])#tf.placeholder(tf.float32,shape=(None,128,128,1),name='inputs')\n",
    "targets = tf.reshape(y_true,[-1,128,128,1])#tf.placeholder(tf.float32,shape=(None,128,128,1),name='targets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1 = tf.layers.conv2d(inputs=inputs,filters=32,kernel_size=(3,3),padding='same',activation=tf.nn.relu)\n",
    "maxpool1 = tf.layers.max_pooling2d(inputs=conv1,pool_size=(2,2),strides=(2,2),padding='same')\n",
    "\n",
    "conv2 = tf.layers.conv2d(inputs=maxpool1,filters=32,kernel_size=(3,3),padding='same',activation=tf.nn.relu)\n",
    "maxpool2 = tf.layers.max_pooling2d(inputs=conv2,pool_size=(2,2),strides=(2,2),padding='same')\n",
    "\n",
    "conv3 = tf.layers.conv2d(inputs=maxpool2,filters=16,kernel_size=(3,3),padding='same',activation=tf.nn.relu)\n",
    "maxpool3 = tf.layers.max_pooling2d(inputs=conv3,pool_size=(2,2),strides=(2,2),padding='same')\n",
    "\n",
    "conv4 = tf.layers.conv2d(inputs=maxpool3,filters=16,kernel_size=(3,3),padding='same',activation=tf.nn.relu)\n",
    "maxpool4 = tf.layers.max_pooling2d(inputs=conv4,pool_size=(2,2),strides=(2,2),padding='same')\n",
    "\n",
    "conv5 = tf.layers.conv2d(inputs=maxpool4,filters=16,kernel_size=(3,3),padding='same',activation=tf.nn.relu)\n",
    "encoded = tf.layers.max_pooling2d(inputs=conv5,pool_size=(2,2),strides=(2,2),padding='same')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "upsampler1 = tf.image.resize_images(encoded,size=(8,8),method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "conv6 = tf.layers.conv2d(inputs=upsampler1,filters=16,kernel_size=(3,3),padding='same',activation=tf.nn.relu)\n",
    "\n",
    "upsampler2 = tf.image.resize_images(conv6,size=(16,16),method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "conv7 = tf.layers.conv2d(inputs=upsampler2,filters=16,kernel_size=(3,3),padding='same',activation=tf.nn.relu)\n",
    "\n",
    "upsampler3 = tf.image.resize_images(conv7,size=(32,32),method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "conv8 = tf.layers.conv2d(inputs=upsampler3,filters=16,kernel_size=(3,3),padding='same',activation=tf.nn.relu)\n",
    "\n",
    "upsampler4 = tf.image.resize_images(conv8,size=(64,64),method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "conv9 = tf.layers.conv2d(inputs=upsampler4,filters=32,kernel_size=(3,3),padding='same',activation=tf.nn.relu)\n",
    "\n",
    "upsampler5 = tf.image.resize_images(conv9,size=(128,128),method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "conv10 = tf.layers.conv2d(inputs=upsampler5,filters=32,kernel_size=(3,3),padding='same',activation=tf.nn.relu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = tf.layers.conv2d(inputs=conv10,filters=1,kernel_size=(3,3),padding='same',activation=None)\n",
    "decoded = tf.nn.sigmoid(logits)\n",
    "loss = tf.nn.sigmoid_cross_entropy_with_logits(labels=targets,logits=logits)\n",
    "cost = tf.reduce_mean(loss)\n",
    "optimizer = tf.train.AdadeltaOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainning loss: 0.6906\n",
      "Trainning loss: 0.6906\n",
      "Trainning loss: 0.6906\n",
      "Trainning loss: 0.6906\n",
      "Trainning loss: 0.6906\n",
      "Trainning loss: 0.6906\n",
      "Trainning loss: 0.6906\n",
      "Trainning loss: 0.6906\n",
      "Trainning loss: 0.6906\n",
      "Trainning loss: 0.6906\n",
      "Trainning loss: 0.6906\n",
      "Trainning loss: 0.6906\n",
      "Trainning loss: 0.6906\n",
      "Trainning loss: 0.6906\n",
      "Trainning loss: 0.6906\n",
      "Trainning loss: 0.6906\n",
      "Trainning loss: 0.6906\n",
      "Trainning loss: 0.6906\n",
      "Trainning loss: 0.6906\n",
      "Trainning loss: 0.6906\n",
      "Trainning loss: 0.6906\n",
      "Trainning loss: 0.6906\n",
      "Trainning loss: 0.6906\n",
      "Trainning loss: 0.6906\n",
      "Trainning loss: 0.6906\n",
      "Trainning loss: 0.6906\n",
      "Trainning loss: 0.6906\n",
      "Trainning loss: 0.6906\n",
      "Trainning loss: 0.6906\n",
      "Trainning loss: 0.6906\n",
      "Trainning loss: 0.6906\n",
      "Trainning loss: 0.6906\n",
      "Trainning loss: 0.6906\n",
      "Trainning loss: 0.6906\n",
      "Trainning loss: 0.6906\n",
      "Trainning loss: 0.6906\n",
      "Trainning loss: 0.6906\n",
      "Trainning loss: 0.6906\n",
      "Trainning loss: 0.6906\n",
      "Trainning loss: 0.6906\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape (0,) for Tensor 'Placeholder_4:0', which has shape '(?, 16384)'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-150-6924871436aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mii\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_no_of_train_samples\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_xy_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m             \u001b[0mbatch_cost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Trainning loss: {:.4f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_cost\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    875\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 877\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    878\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1074\u001b[0m                              \u001b[0;34m'which has shape %r'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1075\u001b[0m                              (np_val.shape, subfeed_t.name,\n\u001b[0;32m-> 1076\u001b[0;31m                               str(subfeed_t.get_shape())))\n\u001b[0m\u001b[1;32m   1077\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1078\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Tensor %s may not be fed.'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot feed value of shape (0,) for Tensor 'Placeholder_4:0', which has shape '(?, 16384)'"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    epochs = 10\n",
    "    batch_size = 100\n",
    "    for e in range(epochs):\n",
    "        for ii in range(total_no_of_train_samples//batch_size):\n",
    "            x_train,y_train = bg.get_xy_batch(batch_size=batch_size)\n",
    "            batch_cost, _ = sess.run([cost,optimizer],feed_dict={x:x_train,y_true:y_train})\n",
    "            print(\"Trainning loss: {:.4f}\".format(batch_cost))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
